---
id: T-305
type: task
status: todo
priority: high
parent_spec: 003-benchmark-cli.md
---

# Metrics Collector

Implement the metrics collection and aggregation system for tracking benchmark statistics in real-time.

## Sub-tasks:

- [x] **Create Metrics struct in `internal/benchmark/metrics.go`**
  - Use `sync/atomic` for counters that are updated frequently from many goroutines
  - Use `sync.RWMutex` for protecting slices that need to be read for snapshots
  - Fields:
    - `survivorsWaiting atomic.Int64` - current survivors in queue
    - `killersWaiting atomic.Int64` - current killers in queue
    - `matchesFormed atomic.Int64` - total matches created
    - `purchases atomic.Int64` - total successful purchases
    - `errors atomic.Int64` - total errors across all operations
    - `mu sync.RWMutex` - protects the slices below
    - `matchLatencies []time.Duration` - time-to-match samples
    - `purchaseLatencies []time.Duration` - purchase latency samples
    - `startTime time.Time` - when benchmark started (for rate calculations)
    - `lastMatchCount int64` - for calculating matches/sec
    - `lastPurchaseCount int64` - for calculating purchases/sec
    - `lastRateUpdate time.Time` - last time rates were calculated
    - `peakMatchesPerSec float64` - highest observed matches/sec
    - `peakPurchasesPerSec float64` - highest observed purchases/sec

---

- [x] **Implement NewMetrics constructor**
  - Signature: `func NewMetrics() *Metrics`
  - Initialize `startTime` to `time.Now()`
  - Initialize `lastRateUpdate` to `time.Now()`
  - Pre-allocate slices: `matchLatencies: make([]time.Duration, 0, 10000)`
  - Pre-allocate slices: `purchaseLatencies: make([]time.Duration, 0, 10000)`

---

- [x] **Implement waiting count methods**
  - `func (m *Metrics) IncrSurvivorsWaiting()` - atomically increment survivors waiting
  - `func (m *Metrics) DecrSurvivorsWaiting()` - atomically decrement survivors waiting
  - `func (m *Metrics) IncrKillersWaiting()` - atomically increment killers waiting
  - `func (m *Metrics) DecrKillersWaiting()` - atomically decrement killers waiting

---

- [x] **Implement RecordMatch method**
  - Signature: `func (m *Metrics) RecordMatch(timeToMatch time.Duration)`
  - Atomically increment `matchesFormed`
  - Lock mutex, append `timeToMatch` to `matchLatencies` slice, unlock
  - Note: Decrementing waiting counts is caller's responsibility

---

- [x] **Implement RecordPurchase method**
  - Signature: `func (m *Metrics) RecordPurchase(latency time.Duration)`
  - Atomically increment `purchases`
  - Lock mutex, append `latency` to `purchaseLatencies` slice, unlock

---

- [x] **Implement RecordError method**
  - Signature: `func (m *Metrics) RecordError()`
  - Atomically increment `errors` counter

---

- [x] **Implement rate calculation in `internal/benchmark/rates.go`**
  - `func (m *Metrics) updateRates()` - called periodically (every 1 second)
  - Calculate `matchesPerSec = (currentMatches - lastMatchCount) / timeDelta`
  - Calculate `purchasesPerSec = (currentPurchases - lastPurchaseCount) / timeDelta`
  - Update `peakMatchesPerSec` if current rate is higher
  - Update `peakPurchasesPerSec` if current rate is higher
  - Store current counts and time for next calculation

---

- [x] **Implement percentile calculation in `internal/benchmark/percentile.go`**
  - Signature: `func Percentile(samples []time.Duration, p float64) time.Duration`
  - If samples is empty, return 0
  - Create sorted copy of samples (don't modify original)
  - Calculate index: `idx := int(float64(len(sorted)-1) * p)`
  - Return `sorted[idx]`
  - Helper: `func Average(samples []time.Duration) time.Duration` - returns mean

---

- [x] **Implement Snapshot method**
  - Signature: `func (m *Metrics) Snapshot() MetricsSnapshot`
  - Acquire read lock on mutex
  - Copy all atomic values and slice contents to snapshot struct
  - Calculate current rates (call `updateRates()` internally)
  - Calculate averages and percentiles for latency slices
  - Release read lock
  - Return populated `MetricsSnapshot`

---

- [x] **Define MetricsSnapshot struct**
  - `SurvivorsWaiting int64`
  - `KillersWaiting int64`
  - `MatchesFormed int64`
  - `MatchesPerSec float64`
  - `AvgTimeToMatch time.Duration`
  - `P95TimeToMatch time.Duration`
  - `P99TimeToMatch time.Duration`
  - `Purchases int64`
  - `PurchasesPerSec float64`
  - `AvgPurchaseLatency time.Duration`
  - `P95PurchaseLatency time.Duration`
  - `P99PurchaseLatency time.Duration`
  - `Errors int64`
  - `ErrorRate float64` - errors / total requests
  - `TotalRequests int64` - matches*2 (join+status) + purchases
  - `ActiveConnections int64` - survivors + killers waiting
  - `PeakMatchesPerSec float64`
  - `PeakPurchasesPerSec float64`
  - `ElapsedTime time.Duration`

---

- [x] **Write unit tests in `internal/benchmark/metrics_test.go`**
  - Test concurrent recording from multiple goroutines (race detector)
  - Test `Percentile()` with known values: P50, P95, P99
  - Test rate calculations with known time intervals
  - Test snapshot consistency (all values from same point in time)
  - Test peak value tracking updates correctly
