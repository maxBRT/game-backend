---
id: T-310
type: task
status: todo
priority: high
parent_spec: 003-benchmark-cli.md
---

# CLI Commands

Implement the cobra CLI commands including the root command and the run command with all flags.

## Sub-tasks:

- [ ] **Create root command in `cmd/root.go`**
  - Define package-level `rootCmd`:
    ```go
    var rootCmd = &cobra.Command{
        Use:   "benchmark-cli",
        Short: "Load testing tool for game backend services",
        Long:  `A CLI tool that stress-tests the matchmaking service and player service store,
    simulating hundreds of concurrent players joining queues and making purchases.`,
        Version: "1.0.0",
    }
    ```
  - Add `init()` function to set up persistent flags if needed

---

- [ ] **Implement Execute function**
  - Signature: `func Execute() error`
  - Simply call: `return rootCmd.Execute()`
  - Called from `main.go`

---

- [ ] **Create run command in `cmd/run.go`**
  - Define package-level `runCmd`:
    ```go
    var runCmd = &cobra.Command{
        Use:   "run",
        Short: "Run a load test against both services",
        Long:  `Spawns simulated players and purchasers to stress-test the matchmaker
    and store services. Displays real-time metrics in a TUI dashboard.`,
        RunE:  runBenchmark,
    }
    ```
  - Register with root in `init()`: `rootCmd.AddCommand(runCmd)`

---

- [ ] **Define flag variables in `cmd/run.go`**
  - Package-level variables:
    ```go
    var (
        survivors       int
        killers         int
        duration        time.Duration
        rampUp          time.Duration
        purchasesPerSec int
    )
    ```

---

- [ ] **Register flags in init()**
  - In `init()` function after `AddCommand`:
    ```go
    runCmd.Flags().IntVar(&survivors, "survivors", 100, "Number of simulated survivor players")
    runCmd.Flags().IntVar(&killers, "killers", 25, "Number of simulated killer players")
    runCmd.Flags().DurationVar(&duration, "duration", 30*time.Second, "How long to run the benchmark")
    runCmd.Flags().DurationVar(&rampUp, "ramp-up", 5*time.Second, "Time to gradually spawn all players")
    runCmd.Flags().IntVar(&purchasesPerSec, "purchases-per-sec", 50, "Target store purchase rate")
    ```

---

- [ ] **Implement flag validation in runBenchmark**
  - Signature: `func runBenchmark(cmd *cobra.Command, args []string) error`
  - Validate at start of function:
    ```go
    if survivors < 0 {
        return fmt.Errorf("--survivors must be non-negative")
    }
    if killers < 0 {
        return fmt.Errorf("--killers must be non-negative")
    }
    if survivors == 0 && killers == 0 {
        return fmt.Errorf("at least one survivor or killer is required")
    }
    if duration <= 0 {
        return fmt.Errorf("--duration must be positive")
    }
    if rampUp < 0 {
        return fmt.Errorf("--ramp-up must be non-negative")
    }
    if rampUp >= duration {
        return fmt.Errorf("--ramp-up must be less than --duration")
    }
    if purchasesPerSec < 0 {
        return fmt.Errorf("--purchases-per-sec must be non-negative")
    }
    ```

---

- [ ] **Implement runBenchmark main logic**
  - Load config: `cfg := config.Load()`
  - Create runner params:
    ```go
    params := benchmark.RunnerParams{
        Survivors:       survivors,
        Killers:         killers,
        Duration:        duration,
        RampUp:          rampUp,
        PurchasesPerSec: purchasesPerSec,
    }
    ```
  - Create runner: `runner, err := benchmark.NewRunner(cfg, params)`
  - Create snapshot channel: `snapshotChan := make(chan benchmark.MetricsSnapshot, 1)`
  - Set up metrics callback to send to channel
  - Create dashboard: `dash := dashboard.New(duration, snapshotChan)`
  - Set up context with cancellation for Ctrl+C handling

---

- [ ] **Implement concurrent dashboard and runner**
  - Start runner in goroutine:
    ```go
    var results *benchmark.Results
    var runErr error
    done := make(chan struct{})
    go func() {
        results, runErr = runner.Start(ctx)
        close(snapshotChan) // Signal dashboard that benchmark is done
        close(done)
    }()
    ```
  - Start dashboard (blocking):
    ```go
    p := tea.NewProgram(dash, tea.WithAltScreen())
    if _, err := p.Run(); err != nil {
        return fmt.Errorf("dashboard error: %w", err)
    }
    ```
  - Wait for runner: `<-done`
  - If runErr != nil, return error

---

- [ ] **Implement printSummary function**
  - Signature: `func printSummary(results *benchmark.Results)`
  - Print formatted output matching spec:
    ```
    Benchmark complete!

    Matchmaker Results:
      Total matches formed:    %s
      Peak matches/sec:        %.1f
      Avg time-to-match:       %s
      P95 time-to-match:       %s
      P99 time-to-match:       %s

    Store Results:
      Total purchases:         %s
      Peak purchases/sec:      %.1f
      Avg latency:             %s
      P95 latency:             %s
      P99 latency:             %s

    Overall:
      Total requests:          %s
      Error rate:              %.2f%%
    ```
  - Use formatting helpers for numbers and durations
  - Use ANSI colors for headers (green for success, red if high error rate)

---

- [ ] **Implement graceful Ctrl+C handling**
  - Set up signal handling:
    ```go
    ctx, cancel := context.WithCancel(context.Background())
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)
    go func() {
        <-sigChan
        cancel()
    }()
    ```
  - Dashboard's quit (q key) should also cancel context

---

- [ ] **Add version command**
  - Cobra provides this automatically when `Version` is set on rootCmd
  - User can run `benchmark-cli --version` or `benchmark-cli version`

---

- [ ] **Write integration tests in `cmd/run_test.go`**
  - Test flag parsing with various values
  - Test validation errors for invalid flag combinations
  - Test that --help displays all flags with descriptions
  - Note: Full integration tests require mock services
